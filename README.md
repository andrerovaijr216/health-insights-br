# Desafio Final de Engenharia de Dados - Health Insights Brasil

## üéØ Objetivo

Este projeto implementa uma pipeline de dados completa para ingerir, transformar e modelar dados p√∫blicos de interna√ß√µes hospitalares do DataSUS. O objetivo √© criar uma fonte de dados confi√°vel e perform√°tica (um Data Mart) para apoiar an√°lises estrat√©gicas de sa√∫de p√∫blica, resolvendo o desafio da "Health Insights Brasil".

## üèõÔ∏è Arquitetura da Solu√ß√£o

A arquitetura segue o modelo Medalh√£o, garantindo governan√ßa e qualidade em cada etapa do processo.

1.  **ü•â Camada Bronze (`bronze_internacoes_sih`):**
    *   **O qu√™:** Reposit√≥rio de dados brutos.
    *   **Como:** Os dados s√£o ingeridos do DataSUS (no nosso caso, a partir de um arquivo `.dbc` convertido para `.csv`) e armazenados em uma tabela Delta no Databricks sem transforma√ß√µes, garantindo a fidelidade √† fonte original.

2.  **ü•à Camada Silver (`stg_sih_internacoes`):**
    *   **O qu√™:** Camada de dados limpos e padronizados.
    *   **Como:** Usando o dbt, criamos uma `view` que l√™ da camada Bronze, renomeia colunas para nomes de neg√≥cio claros, converte tipos de dados (ex: datas) e aplica limpezas b√°sicas.

3.  **ü•á Camada Gold (`fato_internacoes`, `dim_paciente`):**
    *   **O qu√™:** Camada de dados agregados e prontos para o neg√≥cio.
    *   **Como:** Usando o dbt, criamos um modelo dimensional (Star Schema) com tabelas fato e dimens√£o, otimizado para an√°lises e dashboards. A qualidade e a integridade s√£o garantidas por testes de dados.

## üõ†Ô∏è Tecnologias Utilizadas

*   **Processamento e Data Lakehouse:** Databricks
*   **Transforma√ß√£o e Modelagem:** dbt (Data Build Tool)
*   **Ambiente de Desenvolvimento:** GitHub Codespaces
*   **Orquestra√ß√£o (Proposta):** Databricks Workflows
*   **Data Warehouse de Consumo (Proposta):** Snowflake

## üöÄ Como Rodar o Projeto

1.  **Pr√©-requisitos:** Ambiente configurado no GitHub Codespaces com acesso ao Databricks.
2.  **Ingest√£o:** Os dados brutos (`.csv`) s√£o carregados no Databricks via UI, criando a tabela na camada Bronze.
3.  **Transforma√ß√£o:** Navegue at√© a pasta `dbt_project` no terminal e execute:
    ```bash
    # Executa todos os modelos (Bronze -> Silver -> Gold)
    dbt run
    ```
4.  **Teste de Qualidade:** Para garantir a integridade dos dados, execute:
    ```bash
    # Executa todos os testes definidos no schema.yml
    dbt test
    ```

## ‚ú® Inova√ß√£o e Pr√≥ximos Passos

*   **Integra√ß√£o com Snowflake:** As tabelas da camada Gold seriam exportadas para o Snowflake, que serviria como Data Warehouse de consumo para ferramentas de BI, garantindo a separa√ß√£o de cargas de trabalho.
*   **Dashboard em Tempo Quase Real:** Proposta de um dashboard em Streamlit ou Power BI conectado ao Snowflake para monitorar indicadores de sa√∫de, como taxa de interna√ß√µes por CID-10 e por regi√£o.
*   **Orquestra√ß√£o Automatizada:** A pipeline seria orquestrada com Databricks Workflows para rodar diariamente, garantindo que os dados estejam sempre atualizados.